# Commentary on Collaborative Filtering for Implicit Feedback Datasets

Hu et al. propose in their paper a recommendation system for tackling the challenge of recommending users items where there hasn't been any explicit input from part of the user to help with the task, but only implicit feedback in the form of interactions with certain items. They apply their technique to a dataset of shows watched by a number of TV sets, which represent the users; here they quantify the interaction of the users as the number of times the user has watched a show, being this number real-valued (it can be a fraction or multiple times). Being that said, they leave the door open for many more interesting quantifications of interaction, e.g., quantity of times someone bought an item, or whether someone stopped to watch an ad.

These values are used to do two things, create an estimation of preference and a confidence in that preference, where the confidence is higher the higher the value is and is minimal where the value is missing (for which the estimated preference would be zero). These preferences and confidences are then inputed into a regularized minimization expression for SVD to extract the latent factors of the users and items. Because of the need to compute each possible user-item pair, an optimization method is provided, which escalates linearly with the data and re-calculates the cost function for users and items separately, reducing its value in each iteration. After the optimization is done, it is only needed to calculate the dot products of the latent factor vectors of users and items to get the predicted preference, where the top K items will be recommended to the user according to the predicted preferences.

Although leaving the confidences of missing values as uniformly minimal gives a computational advantage, it is not very realistic. If a user likes shows that are very different than certain show, then the confidence with which we may estimate the preference of zero for that show should be higher that normal. Maybe if we precalculate a similarity measure between items according to the interactions of the users, we could compute more realistic confidences for the zero-valued estimated preferences.

As a suggestion to further improve the quality of the recommendation, with just a few explicit data on every user mixed with the implicit data, one could infer how users would act when not liking things, and how they would act when indeed liking them. This would give more light into what to do with missing values and confidences.
